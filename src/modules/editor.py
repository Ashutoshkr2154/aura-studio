import os
import random
from moviepy.editor import (
    VideoFileClip, AudioFileClip, TextClip, CompositeVideoClip, 
    ColorClip, ImageClip, concatenate_videoclips, vfx
)
from moviepy.video.tools.subtitles import SubtitlesClip
from src.config import Config

class VideoEditor:
    
    @staticmethod
    def assemble_video(blueprint, assets):
        """
        AURA 4.5 RENDER-SAFE ASSEMBLY
        Guarantees: No Black Frames, Perfect Sync, Visible Captions.
        """
        print("\nüé¨ EDITOR: Initializing Render-Safe Pipeline...")
        
        # 1. Load Audio (The Master Clock)
        audio_path = assets.get('audio_path')
        if not os.path.exists(audio_path):
            raise Exception("‚ùå CRITICAL: Audio file missing. Cannot render.")
            
        final_audio = AudioFileClip(audio_path)
        master_duration = final_audio.duration
        print(f"‚è±Ô∏è Target Duration: {master_duration:.2f}s")

        # 2. Prepare Visuals (Scene by Scene)
        final_clips = []
        scenes = blueprint['scenes']
        video_paths = assets.get('video_paths', {})
        
        # Calculate exact duration per scene to prevent drift
        # We divide total audio length by number of scenes for even pacing
        # OR use the specific timestamps if your TTS logic provided them.
        # Here we use even pacing for safety unless specific timing exists.
        scene_duration = master_duration / len(scenes)

        for i, scene in enumerate(scenes):
            scene_id = scene['id']
            clip_path = video_paths.get(scene_id)
            
            # --- BLACK FRAME FIX: VALIDATION LOOP ---
            clip = None
            
            # Try to load downloaded clip
            if clip_path and os.path.exists(clip_path):
                try:
                    clip = VideoFileClip(clip_path)
                    # Check for 0-duration or corrupted clips
                    if clip.duration < 0.1 or clip.size[0] == 0:
                        print(f"‚ö†Ô∏è Corrupt clip for Scene {scene_id}. Discarding.")
                        clip = None
                except Exception as e:
                    print(f"‚ö†Ô∏è Error loading clip {scene_id}: {e}")
                    clip = None

            # Fallback 1: Image Fallback (if available)
            if clip is None:
                # Add logic here if you have fallback images
                pass

            # Fallback 2: "Panic Mode" Color Clip (Prevents Crash/Black Video)
            if clip is None:
                print(f"üö® SCENE {scene_id} MISSING! Using Fallback Generator.")
                clip = ColorClip(size=(1080, 1920), color=(20, 20, 30), duration=scene_duration)
                # Optional: Add text saying "Visual Placeholder" if debugging

            # --- RENDER SAFE PROCESSING ---
            
            # A. Force Vertical Aspect Ratio (9:16) - 1080x1920
            # We crop the center to fill the screen
            w, h = clip.size
            target_ratio = 1080 / 1920
            current_ratio = w / h
            
            if current_ratio > target_ratio:
                # Too wide: Crop width
                new_w = int(h * target_ratio)
                clip = clip.crop(x1=(w/2 - new_w/2), width=new_w, height=h)
            else:
                # Too tall: Crop height
                new_h = int(w / target_ratio)
                clip = clip.crop(y1=(h/2 - new_h/2), width=w, height=new_h)
                
            clip = clip.resize((1080, 1920))

            # B. Duration Lock (Fixes Desync)
            # If clip is too short, loop it. If too long, cut it.
            if clip.duration < scene_duration:
                clip = vfx.loop(clip, duration=scene_duration)
            else:
                clip = clip.subclip(0, scene_duration)
                
            clip = clip.set_duration(scene_duration)
            
            final_clips.append(clip)

        # 3. Concatenate Visuals
        # method='compose' prevents some glitches with different codecs
        final_video_clip = concatenate_videoclips(final_clips, method="compose")
        
        # 4. TRIPLE SYNC CHECK
        # Force video to match audio exactly
        final_video_clip = final_video_clip.set_audio(final_audio)
        final_video_clip = final_video_clip.set_duration(master_duration)

        # 5. CAPTIONS (The "Always Visible" Logic)
        print("üìù Generaing Captions...")
        try:
            # We assume a function exists to generate SRT/subs. 
            # If not, we use a simple Overlay Text method based on the script.
            # For AURA 4.5, let's use the Scene Overlay Text which is safer on Cloud.
            
            text_clips = []
            for i, scene in enumerate(scenes):
                txt = scene.get('overlay_text', '').upper()
                if txt:
                    # Create Text Clip
                    # NOTE: On Streamlit Cloud, specific fonts might fail. 
                    # Use 'DejaVu-Sans-Bold' or None (default) for safety.
                    txt_clip = (TextClip(txt, fontsize=70, color='white', font='DejaVu-Sans-Bold', 
                                       stroke_color='black', stroke_width=3, method='caption', size=(900, None))
                                .set_position(('center', 'center'))
                                .set_duration(scene_duration)
                                .set_start(i * scene_duration))
                    text_clips.append(txt_clip)
            
            if text_clips:
                final_video_clip = CompositeVideoClip([final_video_clip] + text_clips)
                
        except Exception as e:
            print(f"‚ö†Ô∏è Caption Error (Skipping to preserve video): {e}")

        # 6. Branding / Watermark
        if assets.get('watermark_text'):
            wm_txt = assets['watermark_text']
            wm = (TextClip(wm_txt, fontsize=30, color='white', font='DejaVu-Sans', opacity=0.6)
                  .set_position(('center', 0.92), relative=True) # Bottom center
                  .set_duration(master_duration))
            final_video_clip = CompositeVideoClip([final_video_clip, wm])

        # 7. Final Export
        output_path = os.path.join(Config.OUTPUT_DIR, f"AURA_{random.randint(1000,9999)}.mp4")
        os.makedirs(Config.OUTPUT_DIR, exist_ok=True)
        
        print("üöÄ Rendering Final Export (This may take 30-60s)...")
        final_video_clip.write_videofile(
            output_path,
            fps=24,
            codec='libx264',
            audio_codec='aac',
            preset='ultrafast',  # 'ultrafast' for speed on Cloud
            threads=4,
            logger=None # Silence FFMPEG logs in terminal
        )
        
        return output_path